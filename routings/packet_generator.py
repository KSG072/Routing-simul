import os, csv
from typing import Sequence, Any, Optional
import numpy as np

from parameters.PARAMS import inclination_deg, altitude_km, N, M, F, TRAFFIC_DENSITY, TRAFFIC_DENSITY_UNIFORM
from utils.walker_constellation import WalkerConstellation


def generate_onoff_event_csvs(
    src_nodes: Sequence[Any],
    dst_nodes: Sequence[Any],
    traffic_duration_ms: int = 20_000,
    num_flows: int = 3000,
    rates_mbps: Optional[Sequence[float]] = None,
    rate_min_mbps: float = 80.0,
    rate_max_mbps: float = 350.0,
    rate_step_mbps: float = 40.0,
    pkt_bits: int = 64_000,
    pareto_alpha: float = 1.5,
    mean_on_ms: float = 500.0,
    mean_off_ms: float = 500.0,
    out_dir: str = "../parameters/traffic",
    seed: Optional[int] = 42,

    # --- ì˜µì…˜ ---
    steady_state_start: bool = True,
    start_on: bool = True,
    warmup_ms: int = 0,

    # ğŸ”½ ê°€ì¤‘ ìƒ˜í”Œë§ ì…ë ¥ (ì„ì˜ ëª¨ì–‘ ì§€ì›: rowsÃ—cols)
    sats_group_by_grid=None,  # rowsÃ—cols, ê° ì…€ì€ ìœ„ì„± ID ë¦¬ìŠ¤íŠ¸
    traffic_map=None          # rowsÃ—cols, ê° ì…€ ê°€ì¤‘ì¹˜ (ìŒìˆ˜ ê¸ˆì§€)
):
    """
    CSV í—¤ë”: time, src_id, dst_id, generated_pkt_num
    """
    if traffic_duration_ms <= 0:
        raise ValueError("traffic_duration_msëŠ” ì–‘ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    if pareto_alpha <= 1.0:
        raise ValueError("pareto_alphaëŠ” 1ë³´ë‹¤ ì»¤ì•¼ í‰ê· ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    if warmup_ms < 0:
        raise ValueError("warmup_msëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    # ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ ê¸¸ì´(ì›Œë°ì—… í¬í•¨)
    sim_duration_ms = traffic_duration_ms + warmup_ms
    sim_max_ms = sim_duration_ms - 1

    rng = np.random.default_rng(seed)

    # ---------- (A) grid ê°€ì¤‘ ë°©ì‹ ì¤€ë¹„ (ëª¨ì–‘ ìë™ ì¸ì‹) ----------
    use_grid_weighted = (sats_group_by_grid is not None) and (traffic_map is not None)

    if use_grid_weighted:
        w = np.array(traffic_map, dtype=np.float64)
        rows, cols = w.shape  # âœ… ì–´ë–¤ ëª¨ì–‘ì´ë“  ì§€ì›
        if np.any(w < 0):
            raise ValueError("traffic_mapì—ëŠ” ìŒìˆ˜ ê°€ì¤‘ì¹˜ë¥¼ ë„£ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ë¹ˆ ì…€(ìœ„ì„± 0ê°œ)ì€ ì„ íƒ ë¶ˆê°€ â†’ ê°€ì¤‘ì¹˜ 0
        nonempty = np.zeros((rows, cols), dtype=bool)
        if len(sats_group_by_grid) != rows or len(sats_group_by_grid[0]) != cols:
            raise ValueError(f"sats_group_by_grid ëª¨ì–‘ {len(sats_group_by_grid)}Ã—{len(sats_group_by_grid[0])} "
                             f"ì™€ traffic_map ëª¨ì–‘ {rows}Ã—{cols} ì´ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")
        for i in range(rows):
            for j in range(cols):
                nonempty[i, j] = len(sats_group_by_grid[i][j]) > 0

        w = w * nonempty  # ë¹ˆ ì…€ì€ ìë™ 0

        if np.all(w == 0):
            # ëª¨ë“  ì…€ì´ ë¹„ì—ˆê±°ë‚˜ ê°€ì¤‘ì¹˜ê°€ 0ì´ë©´ fallback: non-empty ê· ë“±
            w = nonempty.astype(np.float64)

        # ì •ê·œí™” í™•ë¥ ë²¡í„°
        p = w.ravel()
        p_sum = p.sum()
        if p_sum == 0:
            raise ValueError("ì„ íƒ ê°€ëŠ¥í•œ gridê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ì…€ ë¹„ì–´ìˆìŒ)")
        p = p / p_sum

        def sample_two_distinct_grids():
            # rows*cols ì¤‘ 2ê°œ ë¹„ë³µì› ì¶”ì¶œ (ê°€ì¤‘ í™•ë¥ )
            idx2 = rng.choice(rows * cols, size=2, replace=False, p=p)
            i1, j1 = divmod(int(idx2[0]), cols)
            i2, j2 = divmod(int(idx2[1]), cols)
            return (i1, j1), (i2, j2)

        def sample_sat_from_cell(i, j):
            cell = sats_group_by_grid[i][j]
            return rng.choice(cell)

        def choose_pair_via_grid():
            (si, sj), (di, dj) = sample_two_distinct_grids()
            s = sample_sat_from_cell(si, sj)
            d = sample_sat_from_cell(di, dj)
            return s, d

    # ---------- (B) ê¸°ì¡´ ê· ë“± ë°©ì‹ ----------
    else:
        pairs = [(s, d) for s in src_nodes for d in dst_nodes if s != d]
        if not pairs:
            raise ValueError("ìœ íš¨í•œ (src,dst) ìŒì´ ì—†ìŠµë‹ˆë‹¤. (src != dst)")
        pairs = np.array(pairs, dtype=object)
        pair_probs = np.ones(len(pairs), dtype=np.float64) / len(pairs)

    # Pareto ê´€ë ¨
    xm_on_ms  = mean_on_ms  * (pareto_alpha - 1.0) / pareto_alpha
    xm_off_ms = mean_off_ms * (pareto_alpha - 1.0) / pareto_alpha

    def pareto_duration_ms(xm_ms: float) -> float:
        return float(xm_ms * (1.0 + rng.pareto(pareto_alpha)))

    def length_biased_pareto_ms(xm_ms: float) -> float:
        a_lb = pareto_alpha - 1.0
        if a_lb <= 0:
            return pareto_duration_ms(xm_ms)
        return float(xm_ms * (1.0 + rng.pareto(a_lb)))

    def sample_initial_state_and_remaining():
        p_on = mean_on_ms / (mean_on_ms + mean_off_ms)
        on0 = bool(rng.random() < p_on)
        xm0 = xm_on_ms if on0 else xm_off_ms
        L0 = length_biased_pareto_ms(xm0)
        age0 = rng.uniform(0.0, L0)
        remain0 = L0 - age0
        return on0, remain0

    # --- ì†¡ì‹ ë¥  ëª©ë¡ êµ¬ì„± (ì¤‘ë³µ ì œê±°) ---
    if rates_mbps is None:
        grid = np.arange(rate_min_mbps, rate_max_mbps + 1e-9, rate_step_mbps, dtype=float)
        rates = grid[grid <= rate_max_mbps].tolist()
        if len(rates) == 0 or abs(rates[-1] - rate_max_mbps) > 1e-9:
            rates.append(float(rate_max_mbps))
    else:
        rates = [float(r) for r in rates_mbps]
        if any(r <= 0 for r in rates):
            raise ValueError("rates_mbpsì—ëŠ” ì–‘ìˆ˜ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.")

    os.makedirs(out_dir, exist_ok=True)

    # --- í”Œë¡œìš°ë³„ (src,dst) ë¯¸ë¦¬ ë½‘ê¸° ---
    print(f"{num_flows}ê°œì˜ í”Œë¡œìš°ì— ëŒ€í•œ (src, dst) ìŒì„ ë¯¸ë¦¬ ì„ íƒí•©ë‹ˆë‹¤...")
    if use_grid_weighted:
        flow_pairs = [choose_pair_via_grid() for _ in range(num_flows)]
    else:
        flow_pair_indices = rng.choice(len(pairs), size=num_flows, replace=True, p=pair_probs)
        flow_pairs = [pairs[i] for i in flow_pair_indices]

    # --- ì‹œë®¬ë ˆì´ì…˜ ---
    from tqdm import tqdm
    for rate_mbps in rates:
        rate_bps = rate_mbps * 1e6
        dt_ms = (pkt_bits / rate_bps) * 1000.0

        bucket: dict[tuple[int, any, any], int] = {}

        # í”Œë¡œìš°ë³„ (src,dst)ëŠ” ë£¨í”„ ë°–ì—ì„œ ì´ë¯¸ ì„ íƒë¨
        for i in tqdm(range(num_flows), desc=f"Rate {rate_mbps} Mbps"):
            s_id, d_id = flow_pairs[i]

            # ì´ˆê¸°í™”
            if steady_state_start:
                on, first_remain_ms = sample_initial_state_and_remaining()
                first = True
            else:
                on = bool(start_on)
                first = False

            t_ms = 0.0
            while t_ms < sim_duration_ms:
                dur_ms = (first_remain_ms if first else
                          pareto_duration_ms(xm_on_ms if on else xm_off_ms))
                first = False
                t_end_ms = min(t_ms + dur_ms, float(sim_duration_ms))

                if on and (t_end_ms - t_ms) >= dt_ms:
                    n_pkts = int((t_end_ms - t_ms) // dt_ms)
                    if n_pkts > 0:
                        ts_ms = t_ms + np.arange(n_pkts, dtype=np.float64) * dt_ms
                        ms_idx = np.floor(ts_ms + 1e-9).astype(np.int64)
                        np.minimum(ms_idx, sim_max_ms, out=ms_idx)
                        unique_ms, counts = np.unique(ms_idx, return_counts=True)
                        for m, c in zip(unique_ms.tolist(), counts.tolist()):
                            if m >= warmup_ms:
                                key = (int(m - warmup_ms), s_id, d_id)
                                bucket[key] = bucket.get(key, 0) + int(c)

                t_ms = t_end_ms
                on = not on

        out_path = os.path.join(out_dir, f"events_{int(rate_mbps)}Mbps.csv")
        with open(out_path, "w", newline="") as f:
            writer = csv.writer(f, lineterminator="\n")
            writer.writerow(["time", "src_id", "dst_id", "generated_pkt_num"])
            for (t_int, s_id, d_id), cnt in sorted(bucket.items(), key=lambda kv: kv[0][0]):
                if 0 <= t_int < traffic_duration_ms:
                    writer.writerow([t_int, s_id, d_id, cnt])

        print(f"[OK] {out_path}  (dtâ‰ˆ{dt_ms:.6f} ms, flows={num_flows}, "
              f"steady_start={steady_state_start}, warmup={warmup_ms} ms)")


def grouping_satellite_to_lat_lon_grid(
        satellites,
        sats_group_by_grid,
        lat_max_abs: float = 60.0  # |ìœ„ë„|ê°€ ë„˜ì–´ê°€ë©´ ê°€ì¥ìë¦¬ binìœ¼ë¡œ í´ë¨í”„
):
    """
    sats_group_by_grid ëª¨ì–‘(rowsÃ—cols)ì— ìë™ ì ì‘.
    rows: ìœ„ë„ bins, cols: ê²½ë„ bins.
    ê²½ë„ëŠ” ê· ë“± bins(í­ = 360/cols), ìœ„ë„ëŠ” [-lat_max_abs, +lat_max_abs]ë¥¼ rows ë“±ë¶„.
    """
    rows = len(sats_group_by_grid)
    cols = len(sats_group_by_grid[0])

    # ìœ„ë„ bin ë„ˆë¹„
    lat_bin_width = 2 * lat_max_abs / rows

    def lat_to_idx(lat_deg: float) -> int:
        # [-lat_max_abs, lat_max_abs] ë²”ìœ„ ë°–ì˜ ê°’ì€ ê°€ì¥ìë¦¬ binìœ¼ë¡œ ì²˜ë¦¬
        if lat_deg >= lat_max_abs:
            return 0
        if lat_deg <= -lat_max_abs:
            return rows - 1

        # ìœ„ìª½(ë¶ìª½)ë¶€í„° 0ë²ˆ ì¸ë±ìŠ¤. (lat_max_abs - lat)ìœ¼ë¡œ ì¢Œí‘œ ë³€í™˜ í›„ ë„ˆë¹„ë¡œ ë‚˜ëˆ”
        # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ë¡œ ê²½ê³„ê°’ì—ì„œ ì¸ë±ìŠ¤ê°€ ë²—ì–´ë‚˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ min ì‚¬ìš©
        idx = int((lat_max_abs - lat_deg) / lat_bin_width)
        return min(idx, rows - 1)

    def lon_to_idx(lon_deg_0_360: float) -> int:
        # 0..360 ì…ë ¥ì„ -180..180ìœ¼ë¡œ ì´ë™ í›„ ê· ë“± bin
        if lon_deg_0_360 < 180:
            lon = lon_deg_0_360
        else:
            lon = lon_deg_0_360 - 360.0
        # lon = ((lon_deg_0_360 % 360.0) + 180.0) % 360.0 - 180.0  # [-180,180)
        width = 360.0 / cols
        idx = int((np.floor(lon) + 180.0) // width)
        # ë¶€ë™ì†Œìˆ˜ ë°©ì–´
        if idx < 0: idx = 0
        if idx >= cols: idx = cols - 1
        return idx

    grid = sats_group_by_grid
    for sat in satellites:
        # ìœ„ì„± ê°ì²´ì— í•„ìš”í•œ ì†ì„±ì´ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
        lat = float(sat.real_latitude_deg)
        lon0_360 = float(sat.real_longitude_deg)

        li = lat_to_idx(lat)
        lj = lon_to_idx(lon0_360)
        grid[li][lj].append(sat.node_id)

    return grid


if __name__ == "__main__":
    constellation = WalkerConstellation(N=N, M=M, F=F,
                                        altitude_km=altitude_km,
                                        inclination_deg=inclination_deg)
    constellation.generate_constellation()
    satellites_dict = constellation.get_all_satellites()
    satellites = satellites_dict.values()

    # âœ… íŠ¸ë˜í”½ ë§µì˜ ëª¨ì–‘ìœ¼ë¡œ ê·¸ë¦¬ë“œ í¬ê¸° ìë™ ì„¤ì •
    tm = np.array(TRAFFIC_DENSITY, dtype=float)
    rows, cols = tm.shape
    sats_group_by_grid = [[[] for _ in range(cols)] for _ in range(rows)]

    sats_group_by_grid = grouping_satellite_to_lat_lon_grid(
        satellites, sats_group_by_grid,
        lat_max_abs=60.0  # í•„ìš”ì‹œ 75, 90 ë“±ìœ¼ë¡œ ì¡°ì •
    )

    generate_onoff_event_csvs(
        src_nodes=satellites_dict.keys(),
        dst_nodes=satellites_dict.keys(),
        traffic_duration_ms=10_000,
        num_flows=3000,
        rates_mbps=[1, 40, 80, 120, 160, 200, 240, 280, 320, 360],          # ì˜ˆì‹œ
        rate_min_mbps=80,
        rate_max_mbps=360,
        rate_step_mbps=40,
        pkt_bits=64_000,
        pareto_alpha=1.5,
        mean_on_ms=500.0,
        mean_off_ms=500.0,
        seed=42,
        steady_state_start=True,
        start_on=True,
        warmup_ms=2000,
        out_dir="../parameters/uneven traffic(latest)",
        sats_group_by_grid=sats_group_by_grid,
        traffic_map=TRAFFIC_DENSITY   # ğŸ”¥ rowsÃ—cols ì–´ë–¤ í¬ê¸°ë“  OK
    )
